앞전에 캐시 전략 중 Cache Aside 방식과 캐시 불일치 문제를 완화하는 3가지 방법에 대해 포스팅했다.

이렇게 대규모 트래픽 환경에서 캐시를 운용하고, 캐싱 전략으로 Cache Aside 전략을 사용한다고 가정해보자.

이때 수 많은 요청들이 동시에 캐시 미스를 확인하고 원본 DB에서 데이터를 가져와 캐시에 적재하는 상황이 발생할 수 있는데, 이를 `캐시 스탬피드 현상` 혹은 `Thundering Herd` 문제라고 한다.

# 🔥 Cache Stampede(Thundering Herd)

캐시 스탬피드 현상은 원본 데이터베이스와 캐시의 성능을 저하시키는 요인이 된다.

![](https://velog.velcdn.com/images/alstjr971/post/8a92c988-23b1-4636-adfd-4cdd27d6c3d2/image.png)

> 멀티 스레드 환경에서 여러 스레드가 동시에 캐시에 접근하면서 발생하는 문제를 도식화한 그림

위와 같은 상황일 생각해 보자.

1. 스레드 1,2 에서 동시에 데이터 조회 -> Cache Miss 발생
2. 중복 읽기 발생 → 스레드 1,2 가 동시에 DB에 접근하여 READ
3. 중복 쓰기 발생 → 스레드 1,2 가 DB에서 읽어온 데이터를 동시에 캐시에 

💡이러한 성능 저하 문제를 어떻게 최적화 할 수 있을까❓

# 1️⃣ Locking

잠금 방식은 말 그대로 동일 데이터에 접근할 때 먼저 선점한 스레드에게 잠금 권한을 주어 이후 스레드는 밖에서 대기하는 방식이다.

요청 처리 스레드가 <span style="color: #3498db;">해당 캐시 키에 대한 잠금을 획득</span>하고, 사용자 요청에 응답하는 과정 동안에 캐시 적재 작업은 비동기 스레드로 처리할 수 있다.

잠금을 사용하기 때문에 성능 저하 가능성이 존재하며, 잠금 스레드의 실패, 잠금 생명 주기, 데드 락 등 다양한 상황을 고려해야 하는 단점이 존재한다.


# 2️⃣ External Recomputation

외부 재계산 방식은 모든 요청 처리 스레드가 캐시 적재를 수행하지 않는다.

대신 <span style="color: #3498db;">캐시를 주기적으로 모니터링하는 스레드를 별도로 생성해 관리</span>하여 캐시의 만료 시간이 얼마 남지 않은 경우 데이터를 갱신하여 문제를 예방한다.

다시 사용되지 않을 데이터를 포함하여 갱신하기 때문에 불필요 연산이 포함되고, 메모리 공간을 비효율적으로 사용할 가능성이 존재하는 단점이 있다.

# 3️⃣ Probablistic Early Recomputation

확률적 조기 재계산 방식은 캐시 만료 시간이 얼마 남지 않았을 경우 확률이라는 개념을 사용하여 여러 요청 스레드 중에서 적은 수만이 캐시 적재 작업을 수행해 스탬피드 현상을 완화하는 방식이다.

---

> 이외에도, 캐시 만료 전 미리 데이터를 갱신하는 `Cache Preloading`, 만료 시간을 랜덤하게 설정해 동일 시점에 캐시가 만료되는 것을 방지하는 `Random Expiration`, 캐시 만료를 두 단계로 나누는 `Soft TTL & Hard TTL` 등 여러 가지 방식이 존재한다.
